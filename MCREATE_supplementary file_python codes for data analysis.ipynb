{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='XXXX', api_key='XXXXX')    #Use your account credentials\n",
    "plotly.tools.set_config_file(world_readable=False,sharing='private')\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "plotly.offline.init_notebook_mode() \n",
    "from numpy import arange,array,ones\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import log as log\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine cumulative distribtion of two libraries\n",
    "\n",
    "#library 1 data\n",
    "#copy the path of the destination folder where the input data is stored.\n",
    "workspace_directory = \"D:\\\\folder\\\\filelocation1\"  \n",
    "#enter the input data \".csv\" file.\n",
    "file1 = workspace_directory +\"\\\\\" + \"filex1.csv\"\n",
    "refile1 = pd.read_csv(file1)\n",
    "data1 = refile1.column_name1 #mention the column name of the data that is analyzed.\n",
    "x1 = np.sort(data1) \n",
    "y1 = np.arange(1, len(x1)+1)/len(x1)   \n",
    "plt.plot(x1, y1, c='blue', label=\"legend name1\")  #plots in blue, provide legend name\n",
    "\n",
    "#library 2 data - do the same as above if data comes from a different input file\n",
    "workspace_directory = \"D:\\\\folder\\\\filelocation2\"  \n",
    "file2 = workspace_directory +\"\\\\\" + \"filex2.csv\"\n",
    "refile2 = pd.read_csv(file2)\n",
    "data2 = refile2.column_name2 #mention the column name of the data that is analyzed.\n",
    "#data2 = refile1.column_name2  # use this code instead of the previous line if 2nd data comes from the same file as data1.Mention the column name of data.\n",
    "x2 = np.sort(data2) \n",
    "y2 = np.arange(1, len(x2)+1)/len(x2) \n",
    "plt.plot(x2, y2, c='red', label='legend name2')   #plots in red, provide legend name\n",
    "\n",
    "#plot features\n",
    "plt.xscale('log')   #x-axis scale is set to log\n",
    "plt.ylabel('ECDF')  #y-axis label: ECDF - emperical cummulative distribution frequency\n",
    "plt.xlabel('add label')  #mention your label\n",
    "plt.margins(0.02) #keeps data off plot edges\n",
    "plt.title('assign title') # assign a title for the plot\n",
    "plt.legend(loc='upper right')   #legend is displayed on the upper right corner\n",
    "#plt.axis([0,3.5,0,10000000])   #setting axis range is optional \n",
    "#plt.show()   #do not use this option if you want to use the savefig function below.\n",
    "plt.savefig('cummulative_distributionplot.png', format='png', dpi=300)  #save the file as png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using Plotly software to make interactive plots of library distributions\n",
    "\n",
    "#library 1 data\n",
    "#copy the path of the destination folder where the input data is stored.\n",
    "workspace_directory = \"D:\\\\folder\\\\filelocation\"  \n",
    "#enter the input data \".csv\" file.\n",
    "file1 = workspace_directory +\"\\\\\" + \"filex.csv\"\n",
    "refile1 = pd.read_csv(file1)\n",
    "#optional - sort the column by decreasing order of values\n",
    "refile1sort = refile1.sort_values(by= 'column_name1', ascending=False)  #enter the column name\n",
    "#mention column name \"column_name1\" of data to be analyzed\n",
    "data1 = refile1sort.column_name1  \n",
    "#optional; mention the name of the column \"column_namex1\" for hovering text over plot\n",
    "text1 = refile1sort.column_namex1  \n",
    "\n",
    "#for multiple traces on the same plot repeat the above codes \n",
    "file2 = workspace_directory +\"\\\\\" + \"filex2.csv\"\n",
    "refile2 = pd.read_csv(file2)\n",
    "refile2sort = refile2.sort_values(by= 'column_name2', ascending=False)  #enter the column name\n",
    "data2 = refile2sort.column_name2  \n",
    "text2 = refile2sort.column_namex2  \n",
    "\n",
    "trace1 = go.Scatter(\n",
    "        y= data1,  \n",
    "        text = text1, #optional for interactive plot\n",
    "        mode= 'markers',\n",
    "        marker=dict(symbol='circle-open', size=5, color='rgb(206, 137, 0)'),\n",
    "        name= 'legend_name1' \n",
    "        )\n",
    "trace2 = go.Scatter(\n",
    "        y= data2,  \n",
    "        text = text2,   #optional for interactive plot\n",
    "        mode= 'markers',\n",
    "        marker=dict(symbol='circle-open', size=5, color='rgb(102,204,0)'),\n",
    "        name= 'legend_name2' \n",
    "        )\n",
    "\n",
    "data = [trace1, trace2]  #plot all traces\n",
    "\n",
    "#plot layout parameters\n",
    "layout = go.Layout(\n",
    "    title='add plot title',  \n",
    "    #width=800, \n",
    "\t#height=500,\n",
    "    #hovermode = 'closest',\n",
    "    font=dict(\n",
    "            family='Arial, monospace',\n",
    "            size=18,\n",
    "            color='#000000'\n",
    "            ),\n",
    "    xaxis=dict(\n",
    "        title='add xaxis title',\n",
    "        titlefont=dict(\n",
    "            family='Arial, monospace',\n",
    "            size=18,\n",
    "            color='#000000'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='add yaxis title',\n",
    "        #type ='log',\n",
    "        titlefont=dict(\n",
    "            family='Arial, monospace',\n",
    "            size=18,\n",
    "            color='#000000'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.plot(fig, filename='Plotly_interative_lib_distribution.html')\n",
    "py.image.save_as(fig,scale=5, filename='Plotly_interative_lib_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code to determine standard score of a raw data. \n",
    "\n",
    "#copy the path of the destination folder where the input data is stored.\n",
    "workspace_directory = \"D:\\\\folder\\\\filelocation\"  \n",
    "#enter the input data \".csv\" file.\n",
    "file1 = workspace_directory +\"\\\\\" + \"filex.csv\"\n",
    "refile1 = pd.read_csv(file1)\n",
    "data1 = refile1.column_name1 #mention column name of data to be analyzed\n",
    "refile1['std_data1'] = (data1-data1.mean())/data1.std()   #replace string with desired name for the new column with standard score\n",
    "#optional sorting by standard score data\n",
    "refile1_sort = refile1.sort_values(by= 'std_data1', ascending=False)\n",
    "refile1_sort.to_excel('filex_stdscore.xlsx')  #save as excel sheet, replace string with desired file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code to determine the enrichment score of each variant across a whole library (or specific column)\n",
    "\n",
    "#copy the path of the destination folder where the input data is stored.\n",
    "workspace_directory = \"D:\\\\folder\\\\filelocation\"  \n",
    "#enter the input data \".csv\" file.\n",
    "file1 = workspace_directory +\"\\\\\" + \"filex1.csv\"\n",
    "refile1 = pd.read_csv(file1)\n",
    "\n",
    "#mention column name that has the un-normalized raw data\n",
    "data1 = refile1.column_name1\n",
    "#mention column name that is used for normalize the raw data\n",
    "norm = refile1.column_name2\n",
    "\n",
    "data1s = data1.sum()\n",
    "data1n = np.divide(data1,data1s)\n",
    "norms = norm.sum()\n",
    "normn = np.divide(norm,norms)\n",
    "data_n = np.divide(data1n, normn)\n",
    "refile1['data1_enrich'] = np.log10(data_n)  #add a column name for the enrichment data\n",
    "\n",
    "#optional sort by descreasing order of enrichment score\n",
    "refile1sort = refile1.sort_values(by='data1_enrich', ascending=False)\n",
    "\n",
    "refile1sort.to_csv('filex1_data1enrich.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code to plot multiple histograms on the same plot\n",
    "\n",
    "#copy the path of the destination folder where the input data is stored.\n",
    "workspace_directory = \"D:\\\\folder\\\\filelocation\"  \n",
    "#enter the input data \".csv\" file.\n",
    "file1 = workspace_directory +\"\\\\\" + \"filex1.csv\"\n",
    "refile1 = pd.read_csv(file1)\n",
    "#add additional files here\n",
    "file2 = workspace_directory +\"\\\\\" + \"filex2.csv\"\n",
    "refile2 = pd.read_csv(file2)\n",
    "\n",
    "#mention the name of columns that are analyzed from different files\n",
    "x1 = refile1['column_name1']\n",
    "x2 = refile2['column_name2']\n",
    "\n",
    "#log scale\n",
    "data1 = np.log10(x1)\n",
    "data2 = np.log10(x2)\n",
    "\n",
    "#plot multiple histograms together\n",
    "ax = sns.distplot(data1, hist=True, kde=False, label='legend_name1', color='#ff8b94', hist_kws={\"alpha\": 0.5})\n",
    "ax = sns.distplot(data2, hist=True, kde=False,  label='legend_name2', color='#ff2560', hist_kws={\"alpha\": 0.5})\n",
    "ax.set_facecolor(\"#FFFFFF\")\n",
    "plt.savefig('Seaborn_plot_histogram.png', format='png', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#correlation analysis between two libraries\n",
    "\n",
    "#copy the path of the destination folder where the input data is stored.\n",
    "workspace_directory = \"D:\\\\folder\\\\filelocation\"  \n",
    "#enter the input data \".csv\" file.\n",
    "file1 = workspace_directory +\"\\\\\" + \"filex1.csv\"\n",
    "refile1 = pd.read_csv(file1)\n",
    "\n",
    "#mention the column names of data that are analyzed.\n",
    "x = refile1['column_name1']  \n",
    "y = refile1['column_name2']\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "line = slope*x+intercept\n",
    "plt.plot(x, y,'o', x, line, '-k', color='grey')\n",
    "pylab.title('plot title')  #add plot title\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor(\"#FFFFFF\")\n",
    "plt.savefig('Seaborn_correlationplot.png', format='png', dpi=1000)  #save file with desired name\n",
    "print(\"r-squared:\", r_value**2)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"slope:\", slope)\n",
    "print(\"std-err:\", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#primer generator for synthetic library generation\n",
    "\n",
    "\n",
    "#primer generator for 7mer and 11mer AAV9 variants for cloning\n",
    "\n",
    "\n",
    "#heatmap codes for 7mer and 11mer libraries\n",
    "\n",
    "\n",
    "#code for clustering analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
